{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Failed to read 823410688 bytes from input stream! Read 595297615",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\WalidLenovo\\SEAS6800MNB\\USBLLM\\notebooks\\bolt.ipynb Cell 1\u001b[0m line \u001b[0;36m8\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/WalidLenovo/SEAS6800MNB/USBLLM/notebooks/bolt.ipynb#W0sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m MODEL_PATH \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mC:\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mWalidLenovo\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mbolt2.5-generative.model\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/WalidLenovo/SEAS6800MNB/USBLLM/notebooks/bolt.ipynb#W0sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m tokenizer \u001b[39m=\u001b[39m GPT2Tokenizer\u001b[39m.\u001b[39mfrom_pretrained(\u001b[39m\"\u001b[39m\u001b[39mgpt2\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/WalidLenovo/SEAS6800MNB/USBLLM/notebooks/bolt.ipynb#W0sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m model \u001b[39m=\u001b[39m bolt\u001b[39m.\u001b[39;49mGenerativeModel\u001b[39m.\u001b[39;49mload(MODEL_PATH)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/WalidLenovo/SEAS6800MNB/USBLLM/notebooks/bolt.ipynb#W0sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgenerate_response\u001b[39m(user_input):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/WalidLenovo/SEAS6800MNB/USBLLM/notebooks/bolt.ipynb#W0sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     input_tokens \u001b[39m=\u001b[39m tokenizer\u001b[39m.\u001b[39mencode(user_input)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Failed to read 823410688 bytes from input stream! Read 595297615"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2Tokenizer\n",
    "from thirdai import bolt, licensing\n",
    "\n",
    "licensing.activate(\"D2A996-E7598D-DB122B-E29544-951D7A-V3\")\n",
    "\n",
    "MODEL_PATH = \"C:\\\\WalidLenovo\\\\bolt2.5-generative.model\"\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "model = bolt.GenerativeModel.load(MODEL_PATH)\n",
    "\n",
    "\n",
    "def generate_response(user_input):\n",
    "    input_tokens = tokenizer.encode(user_input)\n",
    "    generated_output = model.generate(\n",
    "        input_tokens=input_tokens,\n",
    "        max_predictions=100,\n",
    "        beam_width=3,\n",
    "        temperature=1.2,\n",
    "    )\n",
    "    return tokenizer.decode(generated_output)\n",
    "\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"Enter your text (or 'exit' to quit): \")\n",
    "\n",
    "    if user_input.lower() == \"exit\":\n",
    "        break\n",
    "\n",
    "    response = generate_response(user_input)\n",
    "    print(\"\\nGenerated Output:\")\n",
    "    print(\"------------------\")\n",
    "    print(response)\n",
    "    print(\"------------------\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myusb_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
